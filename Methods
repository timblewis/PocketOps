  The number of total board states is actually very low for Pocket Ops with only 2*3^9=39366 (the 2 is for the current player turn)
positions or 2*3^8=13122 if you don't include positions with all squares filled. This means it is quite easy to iterate over all possible
positions. If we removed the simultaneous selection nature of blocking we would simply solve this problem using a depth first search or
dynamic programming, and backward induction. Start at the positions 8 moves in, use those scores to find the best moves for the positions
7 moves in, and so on until we reach the starting position. At each position the current player would simply always make the decision that
maximizes their score.
  For this type of game however determining the score of a position given the scores from previous positions is a little more difficult
than taking the min or max. At each position we essentially have a weighted version of a rock paper scissors problem. Essentially each
player has a set of moves and each pair of moves has a payoff which is the score of the resulting position. In these games we want to find
the Nash equilibrium which is the position where both players are making best responses to their opponents strategies.  
  Finding the Nash equilibrium of zero sum two player games like this is actually pretty easy using linear programming. However in this
case there is one pair of moves that we don't already know the payoff for, the case where the blocking player successfully blocks the
active players move. This case is dependent upon the exact same position with the other player to move which has the same number of moves
made.  We can remove this dependency by noting that the resulting position is only dependent upon the original position and positions with
a move being made. However the resulting equation is quadratic and not linear. There is such a thing as quadratic programming but this
only allows quadratic terms in the optimization function not the constraints. There may be a way to solve this in general but I don't know
how so I just did some math specific to this game to solve for the score for each position given the payoffs of each move.
  In these rock paper scissors games the Nash equilibrium is usually a randomized strategy and we define the set of moves that are done
with non-zero probability to be the support. A few facts about the support for this game are obvious, the support for the moving player
and the blocking player are the same, the highest payoff moves are in the support and lowest payoff moves are not in the support.
  Suppose we knew the support S, let p(i) be the payoff for player one successfully playing move i, X be the score for the current
position, and Y be the score for the current position except with it being player two's turn. Then by doing some math I found that
X = ((sum_{i in S} p(i)/(p(i)-Y)) - 1)/(sum_{i in S} 1/(p(i) - Y)). So in order to find X and Y for a given position we begin by
estimating X=1 and Y=0 (the maximum and minimum possible scores respectively) and then updating X using the formula and updating Y using
similar formula. Then we repeat this process until X and Y converge to some value. To determine which moves are in the support S we start
by assuming only one move is in the support and add moves until it decreases the calculated value for X.
  Once we've found X and Y we can find the probabilities for the active player's moves and the probabilities for the blocking player as
well. After more math it turns out that an active player playing optimally will play each move i in the support with relative probability
proportional to 1/(p(i) - Y). This means that the higher payoff moves will be played less often. It turns out the optimal blocking player
will play each move i with exact probability (p(i) - X)/(p(i) - Y). This implies that the optimal blocking player will block the higher
payoff moves in the support more often.
